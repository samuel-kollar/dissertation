{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)\n",
    "        \n",
    "def find2(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return root, name\n",
    "\n",
    "# create readable structure from txt file\n",
    "def create_frame_info(fi_name):\n",
    "    with open(fi_name) as f:\n",
    "        frame_info = f.readlines()\n",
    "    return frame_info\n",
    "\n",
    "# create a list of ids present in a readable structure\n",
    "def get_ids_from_txt(frame_info):\n",
    "    ids = []\n",
    "    for line in frame_info:\n",
    "        a, rest = line.split(\",\", 1)\n",
    "        ids.append(int(a))\n",
    "    return(ids)\n",
    "\n",
    "#get set difference\n",
    "def get_difference(a, b):\n",
    "    return list(set(a).difference(set(b)))\n",
    "\n",
    "def remove_rows(dframe, idlist):\n",
    "    dframe = dframe.set_index(\"detection_id\")\n",
    "    dframe = dframe.drop(idlist, axis=0)\n",
    "    return dframe\n",
    "\n",
    "# get all points from a contour and store as a list of tuples\n",
    "def get_contour_points(contour):\n",
    "    cont = contour[2:-1]\n",
    "    tuples = cont.split(\";\")\n",
    "    l = []\n",
    "    for item in tuples:\n",
    "        a, b = item.split(\" \")\n",
    "        l.append((int(a), int(b)))\n",
    "    return l\n",
    "\n",
    "def process_image(img, x, y, cont_points):\n",
    "    mask = np.zeros((100,100))\n",
    "    xdiff = x - 10\n",
    "    ydiff = y - 10\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for (a,b) in cont_points:\n",
    "        v = a - xdiff\n",
    "        u = b - ydiff\n",
    "        xs.append(u)\n",
    "        ys.append(v)\n",
    "        img[u,v] = (0,0,255)\n",
    "        mask[u,v] = 1\n",
    "    return img, mask, xs, ys\n",
    "\n",
    "def normalizedRGB(img):\n",
    "    newimg=np.zeros((img.shape))\n",
    "    for i, row in enumerate(img):\n",
    "        for j, col in enumerate(row):\n",
    "            b,g,r = col\n",
    "            s = b+g+r\n",
    "            newimg[i,j] = (b//s), (g//s), (r//s)\n",
    "    return newimg        \n",
    "\n",
    "def com(img, startpoint, mask):\n",
    "    (xavg, yavg) = startpoint\n",
    "    \n",
    "    nextleft = (xavg, yavg-1)\n",
    "    nextright = (xavg, yavg+1)\n",
    "    nextup = (xavg+1, yavg)\n",
    "    nextdown = (xavg-1, yavg)\n",
    "    \n",
    "    if (mask[nextleft]==0):\n",
    "        mask[nextleft] = 1\n",
    "        com(img, nextleft, mask)\n",
    "    if (mask[nextright]==0):\n",
    "        mask[nextright] = 1\n",
    "        com(img, nextright, mask)\n",
    "    if (mask[nextup]==0):\n",
    "        mask[nextup] = 1\n",
    "        com(img, nextup, mask)\n",
    "    if (mask[nextdown]==0):\n",
    "        mask[nextdown] = 1\n",
    "        com(img, nextdown, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('csvnames.txt', 'r') as f:\n",
    "    csvfiles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static paths to csvs, videos, frame infos, and npys\n",
    "path_to_csvs = \"/media/sam/Sam\\'s Drive/SUBSET/SQL/ALLYEARS/\"\n",
    "videos_dir = \"/media/sam/My Passport/FISH4KNOWLEDGE/f4k_extracted_image/output/summaries/\"\n",
    "frame_info_dir = \"/media/sam/My Passport/FISH4KNOWLEDGE/f4k_extracted_image/output/summaries/\"\n",
    "npy_dir = \"/media/sam/My Passport/FISH4KNOWLEDGE/final/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename\t\t\t\t\tStatus\t\t% Done\tFrames saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/envs/mlp/lib/python3.7/site-packages/ipykernel_launcher.py:64: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "/home/sam/anaconda3/envs/mlp/lib/python3.7/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in ubyte_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_siteHoBiHu_camera1_201008230800.csv\tDone\t\t100.00% left\t3\n",
      "data_siteHoBiHu_camera1_201008240800.csv\tDone\t\t100.00% left\t9\n",
      "IndexError in a65000c5e6f0e67bebb7c16a6d5f6269#201008260800, frame 28\n",
      "data_siteHoBiHu_camera1_201008260800.csv\tDone\t\t100.00% left\t52\n",
      "IndexError in ecfd05e98afd954be60d87384896a2f4#201008270800, frame 19\n",
      "IndexError in ecfd05e98afd954be60d87384896a2f4#201008270800, frame 20\n",
      "IndexError in ecfd05e98afd954be60d87384896a2f4#201008270800, frame 21\n",
      "IndexError in ecfd05e98afd954be60d87384896a2f4#201008270800, frame 22\n",
      "IndexError in ecfd05e98afd954be60d87384896a2f4#201008270800, frame 27\n",
      "IndexError in ecfd05e98afd954be60d87384896a2f4#201008270800, frame 35\n",
      "data_siteHoBiHu_camera1_201008270800.csv\tDone\t\t100.00% left\t83\n",
      "data_siteHoBiHu_camera1_201008280800.csv\tDone\t\t100.00% left\t107\n",
      "data_siteHoBiHu_camera1_201008290800.csv\tDone\t\t100.00% left\t228\n",
      "data_siteHoBiHu_camera1_201009020800.csv\tDone\t\t100.00% left\t251\n",
      "IndexError in 4960e98115ad3ff5eb26f1ac989f92f8#201009030800, frame 23\n",
      "data_siteHoBiHu_camera1_201009030800.csv\tDone\t\t100.00% left\t296\n",
      "data_siteHoBiHu_camera1_201009040800.csv\tDone\t\t100.00% left\t375\n",
      "data_siteHoBiHu_camera1_201009060800.csv\tUnknownE\t\t100.00% left\t375\n"
     ]
    }
   ],
   "source": [
    "print(\"Filename\\t\\t\\t\\t\\tStatus\\t\\t% Done\\tFrames saved\".format())\n",
    "total = 4521\n",
    "done = 0\n",
    "index_error = []\n",
    "others = []\n",
    "saved_imgs = 0\n",
    "for csvname in csvfiles:\n",
    "    try:\n",
    "        # format name to get full path to csv\n",
    "        csv_path = path_to_csvs + csvname[:-1]\n",
    "\n",
    "        # create initial dataframe\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # get video ID from current df\n",
    "        videoID = df.iloc[0][4][1:]\n",
    "        # get names for files\n",
    "        video_name_fix = \"summary_\" + videoID + \".avi\"\n",
    "        npy_name_fix = videoID + \".RESULT.npy\"\n",
    "        frame_info_fix = \"frame_info_\" + videoID + \".txt\"\n",
    "\n",
    "        # get paths to video, frame info and npy\n",
    "        videopath, videoname = find2(video_name_fix, videos_dir)\n",
    "        video_path = videopath + \"/\" + videoname\n",
    "        frame_info_path = find(frame_info_fix, frame_info_dir)\n",
    "        npy_path = find(npy_name_fix, npy_dir)\n",
    "\n",
    "        # get ids from frame info file and from df, remove rows from df that dont exist in frame info\n",
    "        frame_info_file = create_frame_info(frame_info_path)\n",
    "        frame_info_ids = get_ids_from_txt(frame_info_file)\n",
    "        df_ids = df[\"detection_id\"].tolist()\n",
    "        ids_to_remove = get_difference(df_ids, frame_info_ids)\n",
    "        clean_df = remove_rows(df, ids_to_remove)\n",
    "\n",
    "        # load npy file, this is used together with video to produce images\n",
    "        npy = np.load(npy_path)\n",
    "        vidcap = cv2.VideoCapture(video_path)\n",
    "        success,image = vidcap.read()\n",
    "        # counts every iteration\n",
    "        count = 0\n",
    "        # initialize df where we will save stats\n",
    "        stats = pd.DataFrame(columns=[\"B\", \"G\", \"R\", \"nB\", \"nG\", \"nR\"])\n",
    "        stats.index.name = \"detection_id\"\n",
    "\n",
    "        while success:\n",
    "            if (npy[count]):\n",
    "                index = str(clean_df.index[count])\n",
    "                # save original image\n",
    "                imgpath = \"output/img/\"+videoID+\"#\"+index+\".jpg\"\n",
    "                contour = clean_df.iloc[count][13]\n",
    "                x = clean_df.iloc[count][5]\n",
    "                y = clean_df.iloc[count][6]\n",
    "                contour_points = get_contour_points(contour)\n",
    "                cont_img, mask, xs, ys = process_image(image, x, y, contour_points)\n",
    "                # save image with contour\n",
    "                contpath = \"output/a/\"+videoID+\"#\"+index+\".jpg\"\n",
    "        #         plt.imshow(cont_img)\n",
    "        #         plt.show()\n",
    "\n",
    "\n",
    "                xavg = int(np.mean(xs))\n",
    "                yavg = int(np.mean(ys))\n",
    "                # set coordinates for CoM point\n",
    "                startpoint = (xavg, yavg)\n",
    "\n",
    "                # compute CoM-based shape\n",
    "                try:\n",
    "                    com(cont_img, startpoint, mask)\n",
    "                    cv2.imwrite(imgpath, image)\n",
    "                    cv2.imwrite(contpath, cont_img)\n",
    "                except IndexError:\n",
    "                    print(\"{}\\tIndexE\\t\\t{:2.2f}% left\\t{}\".format(csvname[:-1], percent, saved_imgs))\n",
    "                    count+= 1\n",
    "                    success, image = vidcap.read()\n",
    "                    continue\n",
    "                # extract specific channels\n",
    "                channel0 = image[:,:,0]\n",
    "                channel1 = image[:,:,1]\n",
    "                channel2 = image[:,:,2]\n",
    "                # compute averages\n",
    "                c0avg = np.mean(mask*channel0)\n",
    "                c1avg = np.mean(mask*channel1)\n",
    "                c2avg = np.mean(mask*channel2)\n",
    "                # compute normalized image\n",
    "                normRGB = normalizedRGB(image)\n",
    "                # extract normalized RGB channels\n",
    "                normc0 = normRGB[:,:,0]\n",
    "                normc1 = normRGB[:,:,1]\n",
    "                normc2 = normRGB[:,:,2]\n",
    "                # compute averages\n",
    "                normc0avg = np.mean(mask*normc0)\n",
    "                normc1avg = np.mean(mask*normc1)\n",
    "                normc2avg = np.mean(mask*normc2)\n",
    "                # save to dataframe\n",
    "                stats.loc[index] = [c0avg, c1avg,c2avg, normc0avg, normc1avg, normc2avg]\n",
    "                saved_imgs+=1\n",
    "            count+= 1\n",
    "            success, image = vidcap.read()\n",
    "\n",
    "        csvpath = \"output/csv/\"+videoID+\".csv\"\n",
    "        stats.to_csv(csvpath)\n",
    "        percent = 100 - (done / total)\n",
    "        print(\"{}\\tDone\\t\\t{:2.2f}% left\\t{}\".format(csvname[:-1], percent, saved_imgs))\n",
    "    #     except IndexError:\n",
    "    #         index_error.append(csvname)\n",
    "    #         print(\"!!!: {} index error.\\t{:2.2f}% left\".format(csvname[:-1], percent))\n",
    "    #         continue\n",
    "    except:\n",
    "        others.append(csvname)\n",
    "        print(\"{}\\tUnknownE\\t\\t{:2.2f}% left\\t{}\".format(csvname[:-1], percent, saved_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename\t\t\t\t\tStatus\t\t% Done\tFrames saved\n"
     ]
    }
   ],
   "source": [
    "print(\"Filename\\t\\t\\t\\t\\tStatus\\t\\t% Done\\tFrames saved\".format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format name to get full path to csv\n",
    "csv_path = path_to_csvs + broken_file[:-1]\n",
    "\n",
    "# create initial dataframe\n",
    "df = pd.read_csv(csv_path)\n",
    "# get video ID from current df\n",
    "videoID = df.iloc[0][4][1:]\n",
    "# get names for files\n",
    "video_name_fix = \"summary_\" + videoID + \".avi\"\n",
    "npy_name_fix = videoID + \".RESULT.npy\"\n",
    "frame_info_fix = \"frame_info_\" + videoID + \".txt\"\n",
    "\n",
    "# get paths to video, frame info and npy\n",
    "videopath, videoname = find2(video_name_fix, videos_dir)\n",
    "video_path = videopath + \"/\" + videoname\n",
    "frame_info_path = find(frame_info_fix, frame_info_dir)\n",
    "npy_path = find(npy_name_fix, npy_dir)\n",
    "\n",
    "# get ids from frame info file and from df, remove rows from df that dont exist in frame info\n",
    "frame_info_file = create_frame_info(frame_info_path)\n",
    "frame_info_ids = get_ids_from_txt(frame_info_file)\n",
    "df_ids = df[\"detection_id\"].tolist()\n",
    "ids_to_remove = get_difference(df_ids, frame_info_ids)\n",
    "clean_df = remove_rows(df, ids_to_remove)\n",
    "\n",
    "# load npy file, this is used together with video to produce images\n",
    "npy = np.load(npy_path)\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "success,image = vidcap.read()\n",
    "# counts every iteration\n",
    "count = 0\n",
    "# initialize df where we will save stats\n",
    "stats = pd.DataFrame(columns=[\"B\", \"G\", \"R\", \"nB\", \"nG\", \"nR\"])\n",
    "stats.index.name = \"detection_id\"\n",
    "\n",
    "while success:\n",
    "    if (npy[count]):\n",
    "        index = str(clean_df.index[count])\n",
    "        # save original image\n",
    "        imgpath = \"output/img/\"+videoID+\"#\"+index+\".jpg\"\n",
    "        cv2.imwrite(imgpath, image)\n",
    "        contour = clean_df.iloc[count][13]\n",
    "        x = clean_df.iloc[count][5]\n",
    "        y = clean_df.iloc[count][6]\n",
    "        contour_points = get_contour_points(contour)\n",
    "        cont_img, mask, xs, ys = process_image(image, x, y, contour_points)\n",
    "        # save image with contour\n",
    "        contpath = \"output/a/\"+videoID+\"#\"+index+\".jpg\"\n",
    "#         plt.imshow(cont_img)\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "        xavg = int(np.mean(xs))\n",
    "        yavg = int(np.mean(ys))\n",
    "        # set coordinates for CoM point\n",
    "        startpoint = (xavg, yavg)\n",
    "        cont_img[xavg, yavg] = (255, 0, 0)\n",
    "        \n",
    "        \n",
    "        cv2.imwrite(contpath, cont_img)\n",
    "        # compute CoM-based shape\n",
    "#         com(cont_img, startpoint, mask)\n",
    "\n",
    "#         # extract specific channels\n",
    "#         channel0 = image[:,:,0]\n",
    "#         channel1 = image[:,:,1]\n",
    "#         channel2 = image[:,:,2]\n",
    "#         # compute averages\n",
    "#         c0avg = np.mean(mask*channel0)\n",
    "#         c1avg = np.mean(mask*channel1)\n",
    "#         c2avg = np.mean(mask*channel2)\n",
    "#         # compute normalized image\n",
    "#         normRGB = normalizedRGB(image)\n",
    "#         # extract normalized RGB channels\n",
    "#         normc0 = normRGB[:,:,0]\n",
    "#         normc1 = normRGB[:,:,1]\n",
    "#         normc2 = normRGB[:,:,2]\n",
    "#         # compute averages\n",
    "#         normc0avg = np.mean(mask*normc0)\n",
    "#         normc1avg = np.mean(mask*normc1)\n",
    "#         normc2avg = np.mean(mask*normc2)\n",
    "#         # save to dataframe\n",
    "#         stats.loc[index] = [c0avg, c1avg,c2avg, normc0avg, normc1avg, normc2avg]\n",
    "\n",
    "    count+= 1\n",
    "    success, image = vidcap.read()\n",
    "\n",
    "# csvpath = \"output/csv/\"+videoID+\".csv\"\n",
    "# stats.to_csv(csvpath)\n",
    "# percent = 100 - (done / total)\n",
    "# print(\"{} done.\\t\\t\\t{:2.2f}% left\".format(csvname[:-1], percent))\n",
    "# except IndexError:\n",
    "# index_error.append(csvname)\n",
    "# print(\"!!!: {} index error.\\t{:2.2f}% left\".format(csvname[:-1], percent))\n",
    "# continue\n",
    "# except:\n",
    "# others.append(csvname)\n",
    "# print(\"!!!: {} unknown reason.\\t{:2.2f}% left\".format(csvname[:-1], percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture(video_path)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "frames = 0\n",
    "while success:\n",
    "    if (npy[count]):\n",
    "        frames+=1\n",
    "        if(frames==19):\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            cv2.imwrite(\"sad.jpg\", image)\n",
    "    count+=1\n",
    "    success, image = vidcap.read()\n",
    "print(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df.loc[28][\" contour\"]\n",
    "contour_points2 = get_contour_points(c)\n",
    "cont_img, mask, xs, ys = process_image(image, x, y, contour_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
